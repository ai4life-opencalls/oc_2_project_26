{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40e2ea0d",
   "metadata": {},
   "source": [
    "# Detecting the fiducial particles in EM images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08507027",
   "metadata": {},
   "source": [
    "Fiducial particles/markers are used in correlated light and electron microscopy (CLEM) to enable accurate overlaying of fluorescence (LM) and electron microscopy (EM) images. The fiducial particles in EM images appear as bright circular regions with dark central spot. \n",
    "\n",
    "In this notebook, we **detect fiducial particles** in **EM images** using the template matching algorithm. As a template we use an artificially generated bright image with dark spot in the middle that resembles with its appearence the central part of the fiducial particle. After matching this template to the individual fiducial particles we detect fiducial clusters that consists of at least three fiducial particles in close proximity of each other. The main steps of this algorithm are:\n",
    "- **1. Fiducial particle detection** - Detection of fiducial particles using the template matching algorithm.\n",
    "- **2. Cluster detection** - Filtering the set of individual fiducial particles by recognizing clusters of touching fiducial particles and replacing these clusters by their centroid positions.\n",
    "- **3. Results saving** - Saving the positions of all detected fiducial particles and the positions of fiducial clusters into files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91991e39",
   "metadata": {},
   "source": [
    "Load the necessary python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc93023",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from utils import plot_image, list_to_dataframe, dataframe_to_nparray, dataframe_to_xml, dataframe_to_pointcloud, dataframe_to_xml_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaba3ab",
   "metadata": {},
   "source": [
    "Set the path to the input EM image and values for the parameters, load the EM image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c83a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Load the imput EM image and template\n",
    "input_folder = 'E:/DATA/AI4Life_Pr26/20240805_Trial_data_fiducial_particles/240723_JB294_CLEM-AI4life_sample1/pos2'\n",
    "image_path = Path(os.path.join(input_folder, \"240726_JB295_HEK293_CLEM_LAMP1-488_Particles-555_grid4_pos2_bin2_EM.tif\"))\n",
    "\n",
    "#image_path = Path('E:/DATA/AI4Life_Pr26/20240805_Trial_data_fiducial_particles/240723_JB294_CLEM-AI4life_sample1/pos1/240726_JB295_HEK293_CLEM_LAMP1-488_Particles-555_grid4_pos1_bin4_EM_small.tif')\n",
    "#image_path = Path('E:/DATA/AI4Life_Pr26/20240805_Trial_data_fiducial_particles/240723_JB294_CLEM-AI4life_sample1/pos2/240726_JB295_HEK293_CLEM_LAMP1-488_Particles-555_grid4_pos2_bin4_EM.tif')\n",
    "#image_path = Path('E:/DATA/AI4Life_Pr26/20240805_Trial_data_fiducial_particles/240723_JB294_CLEM-AI4life_sample1/pos3/240726_JB295_HEK293_CLEM_LAMP1-488_Particles-555_grid4_pos3_bin4_EM.tif')\n",
    "print(image_path.exists())\n",
    "\n",
    "output_folder = Path(os.path.join(input_folder,\"output\"))\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "test_folder = Path('//vironova.com/root/Users/kristinal/Documents/1Test')\n",
    "\n",
    "#template_path = Path('E:/DATA/AI4Life_Pr26/20240805_Trial_data_fiducial_particles/240723_JB294_CLEM-AI4life_sample1/pos1/240726_JB295_HEK293_CLEM_LAMP1-488_Particles-555_grid4_pos1_bin4_EM_template.tif')\n",
    "#print(template_path.exists())\n",
    "\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "#template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Parameters for template generation    #Sample1/bin 2 needs size 11, otherwise size 9 works fine\n",
    "template_size = 9     # Create an empty template of size ('size','size') filled with constant value - 'value',9,11\n",
    "template_value = 80    #80,90\n",
    "\n",
    "# Parameters for template matching\n",
    "matching_threshold = 0.7  # threshold for template matching\n",
    "overlap_threshold =0.1\n",
    "\n",
    "# Get template dimensions\n",
    "#h, w = template.shape\n",
    "\n",
    "# Information about fiducial particles\n",
    "fiducial_diam = 27     # diameter of fiducial particles in px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b4cd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "def normalize_image(image):\n",
    "    min_val = np.min(image)\n",
    "    max_val = np.max(image)\n",
    "    return ((image - min_val) / (max_val - min_val) * 255).astype(np.uint8)\n",
    "\n",
    "def standardize_image(image):\n",
    "    mean = np.mean(image)\n",
    "    std = np.std(image)\n",
    "    corrected = (image - mean) / std\n",
    "    corrected = exposure.rescale_intensity(corrected, in_range='image', out_range=(0, 1))\n",
    "    corrected = np.uint8(corrected*255)\n",
    "    return corrected\n",
    "\n",
    "standardized_image = standardize_image(image)\n",
    "normalized_image = normalize_image(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da42e6e",
   "metadata": {},
   "source": [
    "Perform the illumination correction on the image to make the algorithm more robust:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5851ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import rescale, resize\n",
    "from skimage import io, filters, color, exposure\n",
    "\n",
    "def illumination_correction(image, sigma=80):\n",
    "    image_rescaled = rescale(image, 0.25, anti_aliasing=True)\n",
    "    background = filters.gaussian(image_rescaled, sigma=sigma)\n",
    "    background = resize(background, image.shape, anti_aliasing=True)\n",
    "    corrected = image - background\n",
    "    corrected = filters.gaussian(corrected, sigma=1)         # smooth the image a little bit to make nicer segmentation later\n",
    "    #corrected = filters.median(corrected)         # smooth the image a little bit to make nicer segmentation later\n",
    "    corrected = exposure.rescale_intensity(corrected, in_range='image', out_range=(0, 1))\n",
    "    corrected = np.uint8(corrected*255)\n",
    "    return background, corrected\n",
    "\n",
    "background, corrected_image = illumination_correction(image, 80)\n",
    "\n",
    "fig = plt.figure(figsize=(15,20))\n",
    "ax1 = fig.add_subplot(1,3,1)\n",
    "ax1.imshow(image,cmap=\"gray\")\n",
    "ax1.set_title('Original image')\n",
    "plt.axis('off')\n",
    "\n",
    "ax2 = fig.add_subplot(1,3,3)\n",
    "ax2.imshow(normalized_image,cmap=\"gray\")\n",
    "ax2.set_title('Corrected image')\n",
    "plt.axis('off')\n",
    "\n",
    "ax1 = fig.add_subplot(1,3,2)\n",
    "ax1.imshow(background,cmap=\"gray\")\n",
    "ax1.set_title('Background')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5e1cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(image))\n",
    "print(np.mean(normalized_image))\n",
    "print(np.mean(standardized_image))\n",
    "print(np.mean(corrected_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08855bd",
   "metadata": {},
   "source": [
    "## 1. Fiducial particle detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe27593",
   "metadata": {},
   "source": [
    "### Creating a template for the template matching\n",
    "\n",
    "Fiducial particles have a very distinct central region, characterized by a dark spot surrounded by a lighter gray region. Instead of attempting to match the entire particle using a full template, we focus on detecting the central region only. To accomplish this, the template can be easily generated artificially. We create an initial example template of size (9,9). This example template will be immediately resized to the desired template size which was set up earlier using parameter 'template_size'.\n",
    "\n",
    "Using a full particle template did not work satisfactory because of the variaty of the region around the particle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f35a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the template as an empty template of size ('size','size') filled with constant value - 'value'\n",
    "example_template = np.full((9, 9), template_value, dtype=np.uint8)\n",
    "\n",
    "# Define the 3x3 pattern\n",
    "template_pattern = np.array([[4, 2, 4],\n",
    "                             [2, 0, 2],\n",
    "                             [4, 2, 4]])\n",
    "\n",
    "# Calculate the starting index to place the pattern in the middle of the template\n",
    "s_idx = (example_template.shape[0] - template_pattern.shape[0]) // 2\n",
    "e_idx = s_idx + template_pattern.shape[0]\n",
    "    \n",
    "# Place the pattern in the middle of the template\n",
    "example_template[s_idx:e_idx, s_idx:e_idx] = template_pattern\n",
    "\n",
    "#import bigfish.stack as stack\n",
    "#template = stack.resize_image(template,(template.shape[0]*2,template.shape[0]*2), method='bilinear')\n",
    "\n",
    "example_template = example_template.astype(np.uint8)\n",
    "template = cv2.resize(example_template, (template_size,template_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4d94ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(template,(10))\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20163dd0",
   "metadata": {},
   "source": [
    "Helping functions for template matching. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbce146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(boxes, scores, threshold):\n",
    "    # Sort boxes by score in descending order\n",
    "    sorted_indices = np.argsort(scores)[::-1]\n",
    "    # print(\"Indices: \", sorted_indices)\n",
    "    \n",
    "    keep_boxes = []\n",
    "    \n",
    "    while sorted_indices.size > 0:\n",
    "        # Pick the box with the highest score\n",
    "        box_id = sorted_indices[0]\n",
    "        keep_boxes.append(box_id)\n",
    "        \n",
    "        # Calculate IoU of the picked box with the rest\n",
    "        ious = calculate_iou(boxes[box_id], boxes[sorted_indices[1:]])\n",
    "        \n",
    "        # Remove boxes with IoU over the threshold\n",
    "        keep_indices = np.where(ious < threshold)[0]\n",
    "        \n",
    "        # Update the indices\n",
    "        sorted_indices = sorted_indices[keep_indices + 1]\n",
    "    print(\"Keep boxes: \", keep_boxes)\n",
    "    return keep_boxes\n",
    "\n",
    "def calculate_iou(box, boxes):\n",
    "    # Calculate intersection areas\n",
    "    x1 = np.maximum(box[0], boxes[:, 0])\n",
    "    y1 = np.maximum(box[1], boxes[:, 1])\n",
    "    x2 = np.minimum(box[2], boxes[:, 2])\n",
    "    y2 = np.minimum(box[3], boxes[:, 3])\n",
    "    \n",
    "    intersection_area = np.maximum(0, x2 - x1) * np.maximum(0, y2 - y1)\n",
    "    \n",
    "    # Calculate union areas\n",
    "    box_area = (box[2] - box[0]) * (box[3] - box[1])\n",
    "    boxes_area = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "    union_area = box_area + boxes_area - intersection_area\n",
    "    \n",
    "    # Calculate IoU\n",
    "    iou = intersection_area / union_area\n",
    "    return iou\n",
    "\n",
    "def template_matching(image, template, threshold):\n",
    "    result = cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)\n",
    "    #plot_image(result)\n",
    "    locations = np.where(result >= threshold)\n",
    "    scores = result[locations]\n",
    "    matches = list(zip(*locations[::-1]))\n",
    "\n",
    "    return matches, scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7532633e",
   "metadata": {},
   "source": [
    "Template matching is performed. The matches are first filtered so we ensure that the matches are unique and not overlapping. Then we filter false positives by looking at the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f4703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform template matching\n",
    "matching_threshold = 0.7 #0.68\n",
    "image2 = normalized_image #image #\n",
    "#image2 = standardized_image\n",
    "#image2 = corrected_image\n",
    "matches, scores = template_matching(image2, template, matching_threshold)\n",
    "print('Matches:', len(matches), matches)\n",
    "\n",
    "# Create bounding boxes\n",
    "w, h = template.shape[::-1]\n",
    "boxes = [(x, y, x + w, y + h) for (x, y) in matches]    # x,y is the probably the middle of the box, but it does not matter when calculating \n",
    "                                                        # the box overlap\n",
    "# Apply non-maximum suppression for filtering out overlapping boxes\n",
    "keep_ids = non_max_suppression(np.array(boxes), scores, overlap_threshold)\n",
    "print('Keep ids:',len(keep_ids), keep_ids)\n",
    "\n",
    "# Center the matches\n",
    "loc = [np.asarray(matches[keep_id])+[w//2,h//2] for keep_id in keep_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b5408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def otsu_threshold_1d(data, nbins=100):\n",
    "    # Compute histogram and bin edges\n",
    "    hist, bin_edges = np.histogram(data, bins=nbins)\n",
    "    bin_mids = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "    # Normalize histogram to get probabilities\n",
    "    hist = hist.astype(float)\n",
    "    total = hist.sum()\n",
    "    prob = hist / total\n",
    "\n",
    "    # Cumulative sums and means\n",
    "    cumulative_prob = np.cumsum(prob)\n",
    "    cumulative_mean = np.cumsum(prob * bin_mids)\n",
    "    global_mean = cumulative_mean[-1]\n",
    "\n",
    "    # Compute between-class variance for all thresholds\n",
    "    numerator = (global_mean * cumulative_prob - cumulative_mean) ** 2\n",
    "    denominator = cumulative_prob * (1 - cumulative_prob)\n",
    "    # Avoid division by zero\n",
    "    denominator[denominator == 0] = 1e-10\n",
    "    sigma_b_squared = numerator / denominator\n",
    "\n",
    "    # Find the threshold with the maximum between-class variance\n",
    "    idx = np.argmax(sigma_b_squared)\n",
    "    threshold = bin_mids[idx]\n",
    "    return threshold\n",
    "\n",
    "def average_perimeter_intensity(image, center, radius):\n",
    "    # Create a circular mask\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    cv2.circle(mask, center, radius, 255, 1)\n",
    "    \n",
    "    # Extract perimeter pixels\n",
    "    perimeter_pixels = image[mask == 255]\n",
    "    \n",
    "    # Calculate average intensity\n",
    "    average_intensity = np.mean(perimeter_pixels)\n",
    "    #print(\"Average perimeter intensity: \", average_intensity)\n",
    "    \n",
    "    return average_intensity\n",
    "\n",
    "def average_intensity_square(image, middle, size):\n",
    "    x, y = middle\n",
    "    square = image[y-size:y+size+1, x-size:x+size+1].copy()\n",
    "    return np.mean(square)\n",
    "\n",
    "def average_intensity_square_ring(image, middle, out_size, in_size):\n",
    "    x, y = middle\n",
    "    square = image[y-out_size:y+out_size+1, x-out_size:x+out_size+1].copy()\n",
    "    square[in_size:-in_size,in_size:-in_size]=0\n",
    "    return np.average(square[square!=0])\n",
    "\n",
    "def filter_the_template_matching_results(locs, image, size, out_size, in_size):\n",
    "    intensities_middle = []\n",
    "    intensities_square_ring = []\n",
    "    for loc in locs:\n",
    "        intensities_middle.append(average_intensity_square(image, loc, size)) \n",
    "        intensities_square_ring.append(average_intensity_square_ring(image, loc, out_size, in_size))\n",
    "\n",
    "    thresh_middle = otsu_threshold_1d(intensities_middle, 70)\n",
    "    thresh_square_ring = otsu_threshold_1d(intensities_square_ring, 70)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 10), layout='constrained')\n",
    "    axes[0].hist(intensities_middle, bins=100, color='blue', edgecolor='black')\n",
    "    axes[0].set_title('Histogram of Intensities Middle')\n",
    "    axes[0].set_xlabel('Intensity')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "\n",
    "    # Plot histogram for intensities_square_ring on the second subplot\n",
    "    axes[1].hist(intensities_square_ring, bins=100, color='green', edgecolor='black')\n",
    "    axes[1].set_title('Histogram of Intensities Square Ring')\n",
    "    axes[1].set_xlabel('Intensity')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "\n",
    "    print(\"Threshold middle: \", thresh_middle)\n",
    "    print(\"Threshold square ring: \", thresh_square_ring)\n",
    "\n",
    "    locs1 = [loc for loc in locs if average_intensity_square(image, loc, size) < thresh_middle]                # test 1\n",
    "    locs2 = [loc for loc in locs if average_intensity_square_ring(image, loc, out_size, in_size) < thresh_square_ring]   # test 2\n",
    "    locs3 = [loc for loc in locs1 if average_intensity_square_ring(image, loc, out_size, in_size) < thresh_square_ring]  # only if passed both tests\n",
    "    return locs1, locs2, locs3\n",
    "\n",
    "# Filter the template matching results based on average intensity\n",
    "loc1, loc2, loc3 = filter_the_template_matching_results(loc,  image2, 1, 6, 3) # size of middle square, size of outer square, size of inner square for ring\n",
    "\n",
    "# Draw rectangles around the matched regions\n",
    "img2 = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "for pt in loc1:\n",
    "    cv2.circle(img2, (pt[0] + w , pt[1] + h ), 1, (0, 128, 0), 2)\n",
    "      \n",
    "for pt in loc2:\n",
    "    cv2.circle(img2, (pt[0] - w , pt[1] - h ), 1, (255, 255, 0), 2)\n",
    "\n",
    "for pt in loc3:\n",
    "    cv2.rectangle(img2, (pt[0] - fiducial_diam//2 , pt[1] - fiducial_diam//2 ), (pt[0] + fiducial_diam//2 , pt[1] + fiducial_diam//2), (0, 0, 0), 2)\n",
    "    \n",
    "cv2.imwrite(str(output_folder/'fiducial_detectionttt.png'), img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06eda0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "radius = round(template_size/2)+2  # +1 or +2 \n",
    "#loc = [np.asarray(matches[keep_id])+[w//2,h//2] for keep_id in keep_ids if average_perimeter_intensity(image2, np.asarray(matches[keep_id])+[w//2,h//2], radius) < 110]\n",
    "#loc2 = [np.asarray(matches[keep_id])+[w//2,h//2] for keep_id in keep_ids if average_perimeter_intensity(image2, np.asarray(matches[keep_id])+[w//2,h//2], radius) >= 110]\n",
    "#loc = [np.asarray(matches[keep_id])+[w//2,h//2] for keep_id in keep_ids if average_intensity_square(image, np.asarray(matches[keep_id])+[(w//2)-1,(h//2)-1], 3) < 95] #80,100\n",
    "loc = [np.asarray(matches[keep_id])+[w//2,h//2] for keep_id in keep_ids if average_intensity_square_ring(image2, np.asarray(matches[keep_id])+[w//2,h//2], 6, 3) < 135] #80,100\n",
    "#loc = [np.asarray(matches[keep_id])+[w//2,h//2] for keep_id in keep_ids if average_intensity_square(image, np.asarray(matches[keep_id])+[(w//2)-fiducial_diam//2,(h//2)-fiducial_diam//2], \n",
    "#     \n",
    "#                                                                                                                                       fiducial_diam) < 130] #110\n",
    "\n",
    "#loc2 = [np.asarray(matches[keep_id])+[w//2,h//2] for keep_id in keep_ids if average_intensity_square(image, np.asarray(matches[keep_id])+[(w//2)-fiducial_diam//2,(h//2)-fiducial_diam//2], \n",
    "#                                                                                                                                          fiducial_diam) < 111] #110, 130\n",
    "\n",
    "#loc4 = [np.asarray(matches[keep_id])+[w//2,h//2] for keep_id in keep_ids if average_intensity_square(image, np.asarray(matches[keep_id])+[(w//2)-1,(h//2)-1], 3) >= 100] #80\n",
    "\n",
    "\n",
    "\n",
    "# Draw rectangles around the matched regions\n",
    "img2 = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "#for pt in loc:\n",
    "    #cv2.rectangle(img2, (pt[0] - fiducial_diam//2 , pt[1] - fiducial_diam//2 ), (pt[0] + fiducial_diam//2 , pt[1] + fiducial_diam//2), (0, 255, 0), 2)\n",
    "    #cv2.rectangle(img2, (pt[0] - fiducial_diam//2 , pt[1] - fiducial_diam//2 ), (pt[0] + fiducial_diam//2 , pt[1] + fiducial_diam//2), (0, 255, 0), 2)\n",
    "    # plot points in the middle of the box\n",
    "#     cv2.circle(img2, (pt[0] - w , pt[1] - h ), 1, (0, 255, 0), 2)\n",
    "\n",
    "for pt in loc:\n",
    "    cv2.rectangle(img2, (pt[0] - fiducial_diam//2 , pt[1] - fiducial_diam//2 ), (pt[0] + fiducial_diam//2 , pt[1] + fiducial_diam//2), (255, 255, 0), 2)\n",
    "    \n",
    "    # plot points in the middle of the box\n",
    "    #cv2.circle(img2, (pt[0] - w , pt[1] - h ), 1, (255, 255, 0), 2)\n",
    "\n",
    "for pt in loc3:\n",
    "    #cv2.rectangle(img2, (pt[0] - fiducial_diam//2 , pt[1] - fiducial_diam//2 ), (pt[0] + fiducial_diam//2 , pt[1] + fiducial_diam//2), (255, 255, 0), 2)\n",
    "    \n",
    "    # plot points in the middle of the box\n",
    "    cv2.circle(img2, (pt[0] - w , pt[1] - h ), 1, (0, 255, 0), 2)\n",
    "for pt in loc4:\n",
    "    #cv2.rectangle(img2, (pt[0] - fiducial_diam//2 , pt[1] - fiducial_diam//2 ), (pt[0] + fiducial_diam//2 , pt[1] + fiducial_diam//2), (255, 255, 0), 2)\n",
    "    \n",
    "    # plot points in the middle of the box\n",
    "    cv2.circle(img2, (pt[0] - w , pt[1] - h ), 1, (255, 255, 0), 2)\n",
    "'''\n",
    "cv2.imwrite(str(output_folder/'fiducial_detection8.png'), img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d62db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "avrg_intensity = []\n",
    "for keep_id in keep_ids:\n",
    "     avrg_intensity.append(average_intensity_square_ring(image2, np.asarray(matches[keep_id]), 5, 3))\n",
    "\n",
    "print(avrg_intensity)\n",
    "\n",
    "plt.hist(avrg_intensity, bins=100)  # 'bins' can be adjusted as needed\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Numbers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63593c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "avrg_intensity = [average_intensity_square(image, np.asarray(matches[keep_id])+[(w//2)-radius,(h//2)-radius], radius) for keep_id in keep_ids]\n",
    "#avrg_intensity =  [average_intensity_square(image, np.asarray(matches[keep_id])+[(w//2)-2,(h//2)-2], 2+2) for keep_id in keep_ids]\n",
    "find_peaks(avrg_intensity, 100)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(avrg_intensity, bins=30, edgecolor='black')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Values')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0e4d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plot_image(img2)\n",
    "#plt.savefig(str(output_folder/'fiducial_detection.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162153a1",
   "metadata": {},
   "source": [
    "### Filtering of the detected fiducial particles \n",
    "\n",
    "Clusters of fiducial particles (FP) will be replaced by 1 point located in the centre of the cluster. Single FP will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba5eab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a black image of the same size as img2, then draw filled circles with the radius of FP at the locations \n",
    "# of FP taken from the loc variable, dilate the binary image by circular kernel to connect nearby FP, save the image\n",
    "\n",
    "img_mask = np.zeros_like(img2)\n",
    "for pt in loc:\n",
    "    # draw a filled circle around the fiducial particle\n",
    "    cv2.circle(img_mask, pt, fiducial_diam//2, (255, 255, 255), -1)\n",
    "    # draw a filled rectangle around the fiducial particle\n",
    "    #cv2.rectangle(img_mask, pt, (pt[0] + w, pt[1] + h), (255, 255, 255), -1)\n",
    "\n",
    "# Dilate img_mask by circluar kernel of size 7x7\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))\n",
    "img_mask = cv2.dilate(img_mask, kernel, iterations=1)\n",
    "\n",
    "plot_image(img_mask)\n",
    "plt.savefig(str(output_folder/'fiducial_detection_mask.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bb204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate for each connected component the centroid and the pixel area, if the area is larger then \n",
    "# the area of 3 fiducial particles then keep the FP, save the centroid and the area into a list\n",
    "\n",
    "# Find connected components\n",
    "_, labels = cv2.connectedComponents(img_mask)\n",
    "\n",
    "# Calculate the centroid and area of each connected component\n",
    "centroids = []\n",
    "areas = []\n",
    "\n",
    "for label in np.unique(labels):\n",
    "    if label == 0:             # skip the background\n",
    "        continue\n",
    "    \n",
    "    mask = np.zeros_like(img_mask, dtype=np.uint8)\n",
    "    mask[labels == label] = 1\n",
    "    \n",
    "    moments = cv2.moments(mask)\n",
    "    #print(\"Moments: \", moments)\n",
    "\n",
    "    if moments[\"m00\"] > (3 * math.pi * (fiducial_diam//2)**2) :   # equivalent to the area of 3 fiducial particles\n",
    "        centroids.append((int(moments[\"m10\"] / moments[\"m00\"]), int(moments[\"m01\"] / moments[\"m00\"])))\n",
    "        areas.append(int(moments[\"m00\"]))\n",
    "        #print(moment[\"m00\"])\n",
    "\n",
    "print(\"Centroids: \", centroids)\n",
    "print(\"Areas: \", areas)\n",
    "\n",
    "# Draw the centroids on the original image\n",
    "img3 = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "for centroid in centroids:\n",
    "    cv2.circle(img3, centroid, 5, (0, 255, 0), -1)\n",
    "\n",
    "plot_image(img3)\n",
    "\n",
    "cv2.imwrite(str(output_folder/'fiducial_detection_centroids.png'), img3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b3faf6",
   "metadata": {},
   "source": [
    "#### Save the FP locations and filtered FP locations\n",
    "\n",
    "Save the FP locations and filtered FP locations into a pandas dataframe with columns: 'id', 'name', 'pos_x', 'pos_y'. Then convert dataframe into numpy array of coordinate pairs (X,Y), XML file and PLY file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339ea86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cffbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all detected fiducial particles into a Pandas dataframe\n",
    "\n",
    "target_all_df = list_to_dataframe(loc) #str(output_folder/\"target_all_df.csv\")\n",
    "\n",
    "# target = dataframe_to_nparray(target_all_df)\n",
    "dataframe_to_xml_(target_all_df,str(output_folder/\"target_all.xml\"))                      # str(output_folder/\"target.xml\")\n",
    "target_pcd = dataframe_to_pointcloud(target_all_df, str(output_folder/\"target_all.ply\"))  # \"str(output_folder/target.ply)\"\n",
    "\n",
    "## -----------------------------------------------------------------------------------------------\n",
    "\n",
    "target_filt_df = list_to_dataframe(centroids) #str(output_folder/\"target_filt_df.csv\")\n",
    "\n",
    "#target_filt = dataframe_to_nparray(target_filt_df)\n",
    "dataframe_to_xml_(target_filt_df, str(output_folder/\"target_filtered.xml\"))\n",
    "target_filt_pcd = dataframe_to_pointcloud(target_filt_df, str(output_folder/\"target_filtered.ply\"))  # \"target.ply\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI4Life_OC2_2024_26",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
