{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba4e4c50",
   "metadata": {},
   "source": [
    "## Finding the correspondences between fiducial particle positions in EM and LM images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e624c4e",
   "metadata": {},
   "source": [
    "This notebook demonstrates the automatic detection of correspondences between fiducial particles in EM and LM images, followed by computation of a displacement field and warping of the LM image accordingly.\n",
    "\n",
    "The main steps of the algorithm are:\n",
    "- **1. Loading fiducial particle locations** - Fiducial particle coordinates are loaded from an .xml file for both EM (target) and LM (source) images.\n",
    "- **2. Rescaling LM coordinates** - The LM fiducial coordinates are rescaled to match the coordinate system of the EM image.\n",
    "- **3. Multilevel registration** - The algorithm performs a two-stage registration: first rigid, then non-rigid. It automatically identifies corresponding fiducial particles between the two modalities, assigns them matching IDs, and saves the updated information in the .xml file.\n",
    "- **4. Warping the LM image** - Using the displacement field computed from the matched fiducial points, the LM image is warped to align with the EM image.\n",
    "\n",
    "As an alternative, the updated .xml file (step 3) containing the automatically detected correspondences can be imported into the ec-CLEM software, allowing EM and LM image registration without manual annotation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce99c18e",
   "metadata": {},
   "source": [
    "Load the necessary python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70880430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import bigfish.stack as stack\n",
    "import bigfish.plot as plot\n",
    "from probreg import cpd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "from utils import xml_to_dataframe, dataframe_to_xml, dataframe_to_pointcloud, dataframe_to_xml_\n",
    "from utils import visualize_result_nparray, clean_correspondences, print_transformations, chamfer_distance\n",
    "from utils import convert_to_pcd, save_correspondences_in2df, save_correspondences_in1df\n",
    "from utils_displacement_field import expand_displacement_field, extrapolate_displacement_field, visualize_extended_field\n",
    "from utils_displacement_field import calculate_displacement_vectors, plot_and_save_overlay_images, warp_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bd973a",
   "metadata": {},
   "source": [
    "#### 1. Loading fiducial particle locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e280695",
   "metadata": {},
   "source": [
    "The locations of fiducial particles in EM (target) and LM (source) images were automatically detected using the following notebooks:\n",
    "\n",
    "- Detect_fiducial_particles_in_EM.ipynb\n",
    "- Detect_fiducial_particles_in_LM.ipynb\n",
    "\n",
    "These detections were saved in various formats. For further processing, we load the .xml files into Pandas DataFrames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514f3a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = 'E:/DATA/AI4Life_Pr26/20240805_Trial_data_fiducial_particles/240723_JB294_CLEM-AI4life_sample1/pos1/'\n",
    "\n",
    "# target_xml_clust = \"target_clusters.xml\"\n",
    "target_xml_clust = \"Ground_truth_fiducials_EM_only_clusters.xml\" # Ground truth fiducials\n",
    "target_path_xml_clust = Path(os.path.join(input_folder, 'output', target_xml_clust))\n",
    "print(target_path_xml_clust.exists())\n",
    "\n",
    "# source_xml_clust = 'source_clusters.xml'\n",
    "source_xml_clust = \"Ground_truth_fiducials_LM_only_clusters.xml\" # Ground truth fiducials\n",
    "source_path_xml_clust = Path(os.path.join(input_folder, 'output', source_xml_clust))\n",
    "print(source_path_xml_clust.exists())\n",
    "\n",
    "target_df_clust = xml_to_dataframe(target_path_xml_clust)\n",
    "#print(target_df_clust)\n",
    "source_df_small_clust = xml_to_dataframe(source_path_xml_clust)   # small means it is smaller resolution than target, we need to scale it up\n",
    "#print(source_df_small_clust)\n",
    "\n",
    "# Create output folder if it does not exist\n",
    "output_folder = Path(os.path.join(input_folder,\"output\"))\n",
    "output_folder.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209e0c14",
   "metadata": {},
   "source": [
    "#### 2. Rescaling LM coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9364d2b",
   "metadata": {},
   "source": [
    "Since EM and LM images often differ in size—with LM images typically being much smaller—the coordinates of fiducial points detected in the LM image must be rescaled to match the EM image coordinate system. Without this rescaling, registration becomes difficult or inaccurate, as the two point sets would exist in incompatible spatial references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52a1d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_the_scale(EM_shape, LM_shape):\n",
    "    scale_x = EM_shape[0]/LM_shape[0]\n",
    "    scale_y = EM_shape[1]/LM_shape[1]\n",
    "    return scale_x, scale_y\n",
    "\n",
    "# load the EM and LM images\n",
    "EM_image_path = os.path.join(input_folder, \"240726_JB295_HEK293_CLEM_LAMP1-488_Particles-555_grid4_pos1_bin4_EM.tif\")\n",
    "LM_image_path  = os.path.join(input_folder, \"240726_JB295_HEK293_CLEM_LAMP1-488_Particles-555_grid4_pos1_LM.tif\")\n",
    "\n",
    "EMimage = stack.read_image(EM_image_path)\n",
    "LMimage_small = stack.read_image(LM_image_path)\n",
    "\n",
    "# Find what is the scaling rate between the 2 images\n",
    "scale_y, scale_x = find_the_scale(EMimage.shape, LMimage_small.shape)\n",
    "\n",
    "print(\"Scale x: \",scale_x)  # Scale_x = 22.966165413533833\n",
    "print(\"Scale y: \",scale_y)  # Scale y:  24.873456790123456\n",
    "\n",
    "# Resize the LM point positions\n",
    "source_df_clust = xml_to_dataframe(source_path_xml_clust)\n",
    "source_df_clust['pos_x'] = source_df_small_clust['pos_x']*scale_x\n",
    "source_df_clust['pos_y'] = source_df_small_clust['pos_y']*scale_y\n",
    "\n",
    "# Resize the LM image to fit the position of the resized points\n",
    "LMimage = stack.resize_image(LMimage_small, EMimage.shape, method='bilinear')\n",
    "#EMimage_small = stack.resize_image(EMimage, LMimage_small.shape, method='bilinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67631d3",
   "metadata": {},
   "source": [
    "Plotting the point coordinates on top of the corresponding image allows us to visually verify their correct placement and ensure the coordinates were loaded and scaled properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5555cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot.plot_detection(LMimage_small[:,:,1], source_small, contrast=True)\n",
    "target_clust = target_df_clust[['pos_x', 'pos_y']].to_numpy()\n",
    "source_clust = source_df_clust[['pos_x', 'pos_y']].to_numpy()\n",
    "\n",
    "plot.plot_detection(LMimage[:,:,1], (source_clust[:, [1, 0]]), shape=\"circle\", radius = 3*scale_y, color = \"red\", linewidth = 1, fill=False, contrast=True) \n",
    "plot.plot_detection(EMimage, (target_clust[:, [1, 0]]), radius = 3*scale_y, contrast=False)\n",
    "\n",
    "print(source_clust.shape)\n",
    "print(target_clust.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c325a4",
   "metadata": {},
   "source": [
    "The fiducial points are converted from Pandas DataFrames into point clouds and saved as .ply files for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec3753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_clusters = dataframe_to_pointcloud(target_df_clust, \"target_clusters.ply\")  #target_pcd\n",
    "source_clusters = dataframe_to_pointcloud(source_df_clust, \"source_clusters.ply\")  #source_pcd\n",
    "\n",
    "# Visualize the point cloud\n",
    "#o3d.visualization.draw_geometries([target_clusters])\n",
    "#o3d.visualization.draw_geometries([source_clusters])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba76c48",
   "metadata": {},
   "source": [
    "Loading the coordinates corresponding to the regions of fiducial particles for further analysis or processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf02b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_xml_regi = \"target_regions.xml\"\n",
    "target_xml_regi = \"Ground_truth_fiducials_EM.xml\"  # Ground truth fiducial\n",
    "target_path_xml_regi = Path(os.path.join(input_folder, 'output', target_xml_regi))\n",
    "print(target_path_xml_regi.exists())\n",
    "\n",
    "#source_xml_regi = 'source_regions.xml'\n",
    "source_xml_regi = 'Ground_truth_fiducials_LM.xml' # Ground truth fiducial\n",
    "source_path_xml_regi = Path(os.path.join(input_folder, 'output', source_xml_regi))\n",
    "print(source_path_xml_regi.exists())\n",
    "\n",
    "target_df_regi = xml_to_dataframe(target_path_xml_regi)\n",
    "print(target_df_regi)\n",
    "source_df_small_regi = xml_to_dataframe(source_path_xml_regi)   # small means it is smaller resolution than target, we need to scale it up\n",
    "print(source_df_small_regi)\n",
    "\n",
    "# Resize the LM point positions\n",
    "source_df_regi = xml_to_dataframe(source_path_xml_regi)\n",
    "source_df_regi['pos_x'] = source_df_small_regi['pos_x']*scale_x\n",
    "source_df_regi['pos_y'] = source_df_small_regi['pos_y']*scale_y\n",
    "\n",
    "target_regions = dataframe_to_pointcloud(target_df_regi, \"target_regions.ply\")  #target_pcd\n",
    "source_regions = dataframe_to_pointcloud(source_df_regi, \"source_regions.ply\")  #source_pcd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4c7f70",
   "metadata": {},
   "source": [
    "#### 3. Multilevel registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf077a8",
   "metadata": {},
   "source": [
    "The multilevel registration by Coherent Point Drift (CPD) process consists of two stages:\n",
    "\n",
    " - **Rigid registration** – This initial step uses a smaller number of points, specifically the coordinates of fiducial particle clusters, to align the images through translation, rotation, and scaling.\n",
    "\n",
    "- **Non-rigid registration** – In this stage, a larger set of points is used, including the positions of individual fiducial particles located within the previously identified regions. This allows for finer, local adjustments to account for non-linear distortions between the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2739c6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "# Load the point clouds and set the scale\n",
    "source = o3d.io.read_point_cloud(\"source.ply\") # ('source.ply') ('source_all.ply')\n",
    "target = o3d.io.read_point_cloud(\"target.ply\") # ('target.ply') ('target_all.ply')\n",
    "source_all = o3d.io.read_point_cloud(\"source_all.ply\") # ('source.ply') ('source_all.ply')\n",
    "target_all = o3d.io.read_point_cloud(\"target_all.ply\") # ('target.ply') ('target_all.ply')\n",
    "\n",
    "\n",
    "# Convert to numpy arrays and subscale the points\n",
    "source_points = np.asarray(source.points)/scale         # Subscale the points, so the physical distance between them is not too large\n",
    "target_points = np.asarray(target.points)/scale          # Subscale the points, so the physical distance between them is not too large\n",
    "source_points_all = np.asarray(source_all.points)/scale         # Subscale the points, so the physical distance between them is not too large\n",
    "target_points_all = np.asarray(target_all.points)/scale          # Subscale the points, so the physical distance between them is not too large\n",
    "\n",
    "'''\n",
    "scale = 1000\n",
    "\n",
    "# Convert to numpy arrays and subscale the points\n",
    "source_points = np.asarray(source_clusters.points)/scale         # Subscale the points, so the physical distance between them is not too large\n",
    "target_points = np.asarray(target_clusters.points)/scale          # Subscale the points, so the physical distance between them is not too large\n",
    "source_points_all = np.asarray(source_regions.points)/scale         # Subscale the points, so the physical distance between them is not too large\n",
    "target_points_all = np.asarray(target_regions.points)/scale          # Subscale the points, so the physical distance between them is not too large\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 1st - registration by Coherent Point Drift (CPD) - rigid\n",
    "tf_param_rigid, _, _ = cpd.registration_cpd(source_points, target_points, tf_type_name='rigid', maxiter=1000, tol=1e-5)\n",
    "source_points_res2 = tf_param_rigid.transform(source_points)\n",
    "source_points_all_res2 = tf_param_rigid.transform(source_points_all)\n",
    "\n",
    "#visualize_result_nparray(source_points, target_points, source_points_res2, \"Rigid CPD\")\n",
    "print_transformations(tf_param_rigid, \"Rigid CPD Transformation:\")\n",
    "chamfer_distance(target_points, source_points_res2, \"Chamfer distance 1st - Rigid CPD\")\n",
    "chamfer_distance(target_points_all, source_points_all_res2, \" all Chamfer distance 2nd - Nonrigid CPD\")\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# 2nd - registration by Coherent Point Drift (CPD) - nonrigid \n",
    "tf_param_nonrigid, _, _ = cpd.registration_cpd(source_points_res2, target_points, tf_type_name='nonrigid', maxiter=1000, tol=1e-5)\n",
    "source_points_res3 = tf_param_nonrigid.transform(source_points_res2)\n",
    "\n",
    "tf_param_nonrigid_all, _, _ = cpd.registration_cpd(source_points_all_res2, target_points_all, tf_type_name='nonrigid', maxiter=1000, tol=1e-5)\n",
    "source_points_all_res3 = tf_param_nonrigid_all.transform(source_points_all_res2)\n",
    "\n",
    "#visualize_result_nparray(source_points_res2, target_points, source_points_res3, \"Nonrigid CPD\")\n",
    "print(\"Non-rigid CPD Transformation:\")\n",
    "print(tf_param_nonrigid.g)  # Displacement field\n",
    "print(tf_param_nonrigid.w)  # Weight matrix\n",
    "\n",
    "chamfer_distance(target_points, source_points_res3, \"Chamfer distance 2nd - Nonrigid CPD\")\n",
    "chamfer_distance(target_points_all, source_points_all_res3, \"all Chamfer distance 2nd - Nonrigid CPD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230da44c",
   "metadata": {},
   "source": [
    "Finding correspondences between the points using Point2Point algorithm - This one can be applied to full set of points. Create panda dataframe with the corresponding points having the same \"id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e1d50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.02\n",
    "trans_init = np.asarray([[ 1, 0, 0, 0],  # In trying to have identity matrix as initial transformation so I can instead of source point use result of non-rigid reg points and to the ICP on those\n",
    "                         [ 0, 1, 0, 0],\n",
    "                         [ 0, 0, 1, 0],\n",
    "                         [ 0, 0, 0, 1]])\n",
    "\n",
    "sour = convert_to_pcd(source_points_res3)\n",
    "targ = convert_to_pcd(target_points)\n",
    "sour_all = convert_to_pcd(source_points_all_res3)\n",
    "targ_all = convert_to_pcd(target_points_all)\n",
    "\n",
    "evaluation = o3d.pipelines.registration.evaluate_registration(sour, targ, threshold, trans_init)\n",
    "evaluation_all = o3d.pipelines.registration.evaluate_registration(sour_all, targ_all, threshold, trans_init)\n",
    "print(\"Evaluation: \", evaluation)\n",
    "print(\"Correspondence set: \")\n",
    "print(np.asarray(evaluation.correspondence_set))\n",
    "\n",
    "print(\"Apply point-to-point ICP\")\n",
    "reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "    sour, targ, threshold, trans_init,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "print(reg_p2p)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2p.transformation)\n",
    "\n",
    "#evaluation = o3d.pipelines.registration.evaluate_registration(sour, targ, threshold, reg_p2p.transformation)\n",
    "#evaluation_all = o3d.pipelines.registration.evaluate_registration(sour_all, targ_all, threshold, reg_p2p.transformation)\n",
    "#print(\"Evaluation: \", evaluation)\n",
    "print(\"Correspondence set: \")\n",
    "print(np.asarray(evaluation_all.correspondence_set))\n",
    "\n",
    "\n",
    "correspondences = clean_correspondences(np.asarray(evaluation.correspondence_set))\n",
    "correspondences_all = clean_correspondences(np.asarray(evaluation_all.correspondence_set))\n",
    "print(\"Correspondences: \", correspondences_all)\n",
    "\n",
    "dff2s,dff2t = save_correspondences_in2df(source_points, target_points, correspondences)\n",
    "\n",
    "# This correspondence seems to be working in a way that corresponding point may repeat in the list. \n",
    "# same point can be corresponding to multiple points - fixed by clean_correspondences\n",
    "\n",
    "#orig_source_df = save_correspondences_in1df(np.asarray(orig_source.points), np.asarray(orig_target.points), correspondences)\n",
    "orig_source_df, orig_target_df = save_correspondences_in2df((source_points)/[scale_y,scale_x,1]*scale, \n",
    "                                                            target_points*scale, correspondences)\n",
    "\n",
    "orig_source_all_df, orig_target_all_df = save_correspondences_in2df((source_points_all)/[scale_y,scale_x,1]*scale, \n",
    "                                                            target_points_all*scale, correspondences_all)\n",
    "\n",
    "df = save_correspondences_in1df(source_points_all, target_points_all, correspondences_all)\n",
    "\n",
    "dataframe_to_xml(orig_source_df, 'original_source_points_2205.xml')\n",
    "dataframe_to_xml(orig_target_df, 'original_target_points_2205.xml')\n",
    "dataframe_to_xml(orig_source_all_df, 'original_source_points_all_2205.xml')\n",
    "dataframe_to_xml(orig_target_all_df, 'original_target_points_all_2205.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bed1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "source_database = orig_source_all_df\n",
    "target_database = orig_target_all_df\n",
    "\n",
    "pointsT = np.column_stack((target_database['pos_y'], target_database['pos_x'])) #np.column_stack((target_database['pos_y'], target_database['pos_x']))\n",
    "#pointsT_swapped = [[x, y] for y, x in pointsT]\n",
    "plot.plot_detection(EMimage, pointsT, shape=\"circle\", radius = 3*scale_y, color = \"red\", linewidth = 1, fill=False, contrast=True) \n",
    "\n",
    "pointsS = np.column_stack((source_database['pos_y']*scale_x, source_database['pos_x']*scale_y)) #np.column_stack((target_database['pos_y'], target_database['pos_x']))\n",
    "#pointsT_swapped = [[x, y] for y, x in pointsT]\n",
    "plot.plot_detection(LMimage[:,:,1], pointsS, shape=\"circle\", radius = 3*scale_y, color = \"red\", linewidth = 1, fill=False, contrast=True) \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c367de",
   "metadata": {},
   "source": [
    "#### 4. Warping the LM image\n",
    "\n",
    "The LM image is warped using a displacement field derived from point cloud correspondences between LM and EM images. \n",
    "\n",
    "Since the initial displacement field is defined only within the convex hull of the matched points, it is extrapolated to cover the entire image domain to enable full-image warping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b6705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source_database = orig_source_all_df\n",
    "#target_database = orig_target_all_df\n",
    "#points = np.column_stack((target_database['pos_y'], target_database['pos_x']))  #points = np.column_stack((source_database['pos_x']*scale_x, source_database['pos_y']*scale_y))\n",
    "\n",
    "#displacements = calculate_displacement_vectors(source_database, target_database, scale_x, scale_y)\n",
    "\n",
    "#displacement_field = expand_displacement_field(points, displacements, EMimage.shape)\n",
    "\n",
    "#visualize_extended_field(displacement_field, points)\n",
    "\n",
    "\n",
    "source_database = orig_source_all_df\n",
    "target_database = orig_target_all_df\n",
    "points = np.column_stack((target_database['pos_x'], target_database['pos_y']))  #points = np.column_stack((source_database['pos_x']*scale_x, source_database['pos_y']*scale_y))\n",
    "\n",
    "displacements = calculate_displacement_vectors(source_database, target_database, scale_x, scale_y)\n",
    "\n",
    "points_swapped = [[x, y] for y, x in points]  # here I am swapping the x and y coordinates\n",
    "displacement_field = expand_displacement_field(points_swapped, displacements, EMimage.shape)\n",
    "\n",
    "visualize_extended_field(displacement_field, points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc5f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "extrapolated_field = extrapolate_displacement_field(displacement_field)\n",
    "visualize_extended_field(extrapolated_field, points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6838e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "warped_LMimage = warp_image(LMimage, extrapolated_field.astype(np.float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e148d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_with_points(image, dataframe, scale_y):\n",
    "    points = np.column_stack((dataframe['pos_y'], dataframe['pos_x']))\n",
    "    plot.plot_detection(image, points, shape=\"circle\", radius = 3*scale_y, color = \"red\", linewidth = 1, fill=False, contrast=True) \n",
    "   \n",
    "#pointsT = np.column_stack((target_database['pos_y'], target_database['pos_x'])) #np.column_stack((target_database['pos_y'], target_database['pos_x']))\n",
    "#plot.plot_detection(warped_LMimage, pointsT, shape=\"circle\", radius = 3*scale_y, color = \"red\", linewidth = 1, fill=False, contrast=True) \n",
    "\n",
    "\n",
    "plot_image_with_points(warped_LMimage[:,:,1], target_database, scale_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a606bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_save_overlay_images(EMimage, warped_LMimage[:,:,1], 'overlay_EM_LM_1.png') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI4Life_OC2_2024_26",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
